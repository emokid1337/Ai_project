# Ai_project
Drygin Egor , Vasilev Gleb
# Проект: Прогноз спроса на товары пекарни с помощью нейронных сетей (TensorFlow)

Ссылка на интерактивный ноутбук Google Colab:  
[Colab: Demand Forecasting for Bakery](https://colab.research.google.com/drive/1aKUPtx1T4nt_8qNz8rFQOQtkNO4nuEgx?usp=sharing)

---

## Введение

Современные пекарни работают с высоковариативным спросом: продажи сильно зависят от времени суток, дня недели, сезона и типа товара. Ошибки в прогнозе приводят либо к недопродажам (пустые витрины и упущенная прибыль), либо к списаниям и потерям из‑за несвежей продукции. [file:22][web:108]  

Цель проекта — разработать и реализовать на Python (TensorFlow/Keras) модель нейронной сети для прогноза спроса на различные товары пекарни в зависимости от даты и времени суток, с возможностью интерактивного анализа результатов в Google Colab и HTML‑отчёте. [file:22][web:114]  

Основные задачи:
- Сформировать датасет транзакций пекарни с почасовой агрегированной выручкой/количеством по каждому товару.
- Построить нейронную сеть (Dense/LSTM) для прогноза количества продаж.
- Выполнить количественную оценку качества модели (MAE, MSE, RMSE, MAPE, R²) и визуализировать результаты (динамика обучения, факт vs прогноз, распределение ошибок, анализ по товарам и часам). [file:22][web:75]  

---

## Глава 1. Анализ аналогов и связанных решений

В рамках обзора существующих подходов были рассмотрены следующие типы решений:

- **Классические методы временных рядов**  
  - ARIMA / SARIMA, экспоненциальное сглаживание, модели Holt–Winters, которые хорошо работают на одномерных рядах, но хуже масштабируются при большом числе товаров и сложной сезонности (день недели, праздники, часть дня). [web:108][web:114]  
  - Преимущество: интерпретируемость и простота; недостаток: необходимость ручного подбора параметров и отдельной модели на каждый товар.

- **Машинное обучение для прогноза спроса**  
  - Модели градиентного бустинга (XGBoost, LightGBM), Random Forest и др., использующие агрегированные признаки (lag‑фичи, календарные признаки, кодировка товаров). [web:117][web:75]  
  - Преимущество: работа с множеством признаков и нелинейностями; недостаток: требуется тщательная инженерия признаков и нет встроенного механизма работы с последовательностями.

- **Глубокое обучение и нейронные сети**  
  - LSTM/GRU‑модели, CNN и гибридные архитектуры для временных рядов, позволяющие учитывать сложные зависимости во времени и между товарами. [web:108][web:114]  
  - В открытых примерах показано, что LSTM‑подходы дают выигрыш по RMSE/MAE по сравнению с классическими моделями на задачах прогноза спроса, особенно при наличии нескольких входных признаков (температура, день недели, промо‑акции и т.п.). [web:108][web:111]  

Вывод: в проекте выбран подход с использованием нейронной сети на TensorFlow (Dense и LSTM‑вариант) с калendarными и категориальными признаками, поскольку он лучше отражает сложную сезонность спроса и позволяет применять одинаковую архитектуру для всех товаров одновременно. [web:114]  

---

## Глава 2. Подробное пояснение слайдов 3–8

Ниже приводится текстовое пояснение логики проекта, соответствующее содержанию презентации (слайды 3–8).

### 2.1. Структура данных и подготовка датасета (слайд 3)

Исходные данные — журнал транзакций пекарни `Bakery.csv`, содержащий: идентификатор транзакции, наименование товара, временную метку покупки (`DateTime`) и категориальные признаки дня (`Daypart`, `DayType`). [file:22]  

Данные преобразуются в формат временного ряда:
- Время округляется до часа (или дня) с помощью `dt.floor('h')`.
- По каждой паре (время, товар) считается количество проданных единиц за интервал (агрегация `groupby(['ds', 'Items']).size()`).
- Добавляются календарные признаки: час, день недели, месяц, а также категориальные признаки Daypart (Morning/Afternoon/Evening) и DayType (Weekday/Weekend). [file:22][web:108]  

Для категориальных признаков применяется One‑Hot‑кодирование, что позволяет модели работать с текстовыми признаками в числовом виде. [file:22][web:75]  

### 2.2. Нормализация и разбиение временного ряда (слайд 4)

Для целевой переменной используется лог‑трансформация `log1p(y)`, что уменьшает влияние пиковых значений и стабилизирует дисперсию счётчиков продаж. [file:22][web:62]  

Числовые признаки нормализуются с помощью `StandardScaler`, приводя их к нулевому среднему и единичному стандартному отклонению. Это ускоряет и стабилизирует обучение нейронной сети. [file:22][web:75]  

Разбиение на выборки:
- Данные сортируются по времени.
- Последние 15 % наблюдений выделяются в тестовую выборку (имитируют «будущее»).
- Для обучающей части применяется `TimeSeriesSplit` (5 фолдов), и последний сплит используется как валидационный. Перемешивания нет, чтобы не нарушать временной порядок. [file:22][web:79]  

### 2.3. Архитектура модели (слайды 5–6)

Реализованы два варианта модели на TensorFlow/Keras:

- **Полносвязная модель (Dense)**  
  - Вход: вектор признаков на один временной шаг (календарные + one‑hot категориальные признаки).  
  - Структура: два скрытых слоя размерностью 128 и 64 нейрона с активацией ReLU и Dropout 0.2; выходной слой — один нейрон с линейной активацией для прогноза количества продаж. [file:22][web:114]  
  - Оптимизатор: Adam, скорость обучения 1e‑3, функция потерь — MSE.  

- **LSTM‑модель для временных рядов**  
  - Вход: последовательность длиной 24 часа (окно истории) по тем же признакам.  
  - Архитектура: LSTM(128, `return_sequences=True`) → LSTM(64) → Dropout(0.2) → Dense(1).  
  - Такая архитектура позволяет учитывать динамику спроса, тренды и сезонность внутри суточного окна. [file:22][web:108]  

Ранняя остановка (`EarlyStopping`) отслеживает `val_loss` и прекращает обучение, если метрика не улучшается несколько эпох, возвращая веса лучшей эпохи. [web:114]  

### 2.4. Метрики качества (слайд 7)

Для оценки качества прогноза на тестовой выборке используются следующие метрики (на реальном масштабе, после обратного `expm1`):

- **MAE (Mean Absolute Error)** — средняя абсолютная ошибка прогноза в штуках продаж.  
- **MSE (Mean Squared Error)** — средний квадрат ошибки, чувствителен к крупным промахам.  
- **RMSE (Root MSE)** — корень из MSE, интерпретируемый в тех же единицах, что и спрос.  
- **MAPE (Mean Absolute Percentage Error)** — средняя процентная ошибка прогноза, даёт представление о относительной погрешности.  
- **R² (коэффициент детерминации)** — доля объяснённой вариации спроса нейросетевой моделью. [web:88][web:91]  

Пример полученных значений метрик для настроенной модели (можно подставить фактические цифры из вашего последнего запуска):

- MAE: **0.52**  
- MSE: **0.43**  
- RMSE: **0.66**  
- MAPE: **21.3 %**  
- R²: **0.71**  

(значения являются примером; при согласовании работы преподавателю нужно указать реальные цифры из вашего последнего обучения и зафиксировать их в Colab/HTML‑отчёте).  

### 2.5. Графики и визуальный анализ (слайд 8)

В проекте реализован набор интерактивных графиков на Plotly, входящих в HTML‑отчёт и Colab‑ноутбук: [file:22][web:114]  

- **Динамика функции потерь (MSE) на обучении/валидации**  
  - Линейный график `loss` и `val_loss` по эпохам показывает сходимость модели и момент, когда дальнейшее обучение перестаёт улучшать качество.  

- **Факт vs прогноз по популярному товару**  
  - Временной ряд с двумя линиями (фактический и прогнозируемый спрос) для самого продаваемого товара.  
  - По графику видно, как модель воспроизводит основные пики и провалы спроса в течение дня.  

- **Средний спрос по часам суток: факт vs прогноз**  
  - Группированные столбцы (как на приложенных скриншотах) показывают среднее количество продаж на каждый час, отдельно для факта и прогноза.  
  - По ним оценивается, насколько модель корректно улавливает утренние и вечерние пики продаж.  

- **Распределение ошибок прогнозирования**  
  - Гистограмма `error = y_true − y_pred` демонстрирует смещение и разброс ошибок; симметричное распределение около нуля свидетельствует о несмещённости модели.  

- **Факт vs прогноз по топ‑5 товарам**  
  - Многосерийный временной график для нескольких наиболее популярных изделий; помогает понять, для каких групп товаров модель работает лучше или хуже.  

- **MSE по товарам и временным интервалам**  
  - Столбчатые диаграммы MSE по товарам и по часам суток/дням недели позволяют выявить проблемные зоны (например, редкие товары или вечерние часы с высоким шумом).  

Все эти графики автоматически сохраняются в интерактивном HTML‑отчёте (`bakery_demand_forecasting_report.html`) при запуске основного скрипта/ноутбука и могут быть приложены к отчёту преподавателю как подтверждение корректности экспериментов. [file:22][web:114]  

---

## Как воспроизвести результаты

1. Открыть Colab‑ноутбук по ссылке выше и подключить Google Drive (при необходимости). [web:113]  
2. Загрузить файл `Bakery.csv` в корень проекта или указать путь в конфиге. [file:22]  
3. Последовательно выполнить все ячейки ноутбука:
   - подготовка данных и признаков;
   - обучение модели (Dense или LSTM);
   - оценка метрик;
   - генерация графиков и HTML‑отчёта.  
4. Сохранить значения метрик и ключевые графики для включения в отчёт и презентацию.  

Проект легко расширяется: можно добавлять новые признаки (праздники, акции, погоду), менять архитектуру модели, настраивать длину окон для LSTM и сравнивать качество с другими алгоритмами прогнозирования спроса. [web:108][web:117]  

